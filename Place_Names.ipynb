{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74SuUU4ZSTXn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install stanza\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fX1tqgVlKTuO"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp5JKzqyCcP6"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLFVA0uTM2cu"
   },
   "outputs": [],
   "source": [
    "placez= pd.read_csv('/content/More_Places - Sheet1.csv') #this CSV file is all you need to run all of the code in this notebook\n",
    "placez #manually created spreadsheet of placenames from map I used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgnHYmBn2PHb"
   },
   "outputs": [],
   "source": [
    "def get_pleiades_searchresults(places):\n",
    "  for place in places:\n",
    "    url=f'https://pleiades.stoa.org/search?SearchableText={place}&submit=Search' #searches the general search box in Pleiades\n",
    "    r = requests.get(url)\n",
    "    return (r.content)  #returns the html page of the search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXoXHFf75Q6N",
    "outputId": "33b6d23d-545c-4ced-a801-341f2902ac5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placez_ = list(placez['Original Name'])\n",
    "len(placez_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY44mX3UNjgs"
   },
   "outputs": [],
   "source": [
    "html_results= {}\n",
    "for x in placez_:\n",
    "  try:\n",
    "    get_pleiades_searchresults(x)\n",
    "    if get_pleiades_searchresults(x) in html_results:\n",
    "      continue\n",
    "    else:\n",
    "      html_results[x]= get_pleiades_searchresults(x)  #have to double check the syntax but\n",
    "  except:                                           #an error will be thrown if there is no search result which will stop the code\n",
    "    pass                                            #this will have it skip any name with no results without breaking the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QxRVQ43cnbK"
   },
   "outputs": [],
   "source": [
    "def get_URI_list(soup):\n",
    "  URIs= []\n",
    "  for d in soup.find_all('dt'): #traversing down the html tag tree\n",
    "    for b in d.find_all('span'):\n",
    "      for h in b.find_all('a'):\n",
    "        if h['href'] in URIs: #making sure we don't miss any URIs\n",
    "          continue\n",
    "        else:\n",
    "          URIs.append(h['href'])\n",
    "  return URIs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eNWh-tx4NET"
   },
   "outputs": [],
   "source": [
    "uri_dict= {}\n",
    "for x,y in html_results.items(): #making a dictionary\n",
    "  soup= BeautifulSoup(y)        #ancient place name is the key, value is a list of every URI returned when we searched this name\n",
    "  uri_dict[x]= get_URI_list(soup) #in Pleiades\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcvfGui78H77"
   },
   "outputs": [],
   "source": [
    "urlsDF= pd.DataFrame.from_dict(uri_dict,orient='index') #can convert dict into a dataframe\n",
    "clipped_rez= urlsDF.loc[:, 0:4]\n",
    "clipped_rez #there were a lot of search results #so I am cutting it off at 5\n",
    "            #if I had more time, a better way to do this would be to manually check some of them and see which are more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4DNXxtm8sKM"
   },
   "outputs": [],
   "source": [
    "clipped_rez.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jboOfp1A81LH"
   },
   "outputs": [],
   "source": [
    "urs= clipped_rez.rename(columns= {'index':'Ancient_Name', 0:'URI1',1:'URI2',2:'URI3',3:'URI4',4:'URI5'})\n",
    "urs   #renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zh2r4Kv57PXM"
   },
   "outputs": [],
   "source": [
    "urs.to_csv('/content/drive/MyDrive/GIS/FinalProject/ancientplacesURIs.csv') #saving just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YeRE7E72YFc"
   },
   "outputs": [],
   "source": [
    "urs= pd.read_csv('/content/drive/MyDrive/GIS/FinalProject/ancientplacesURIs.csv')\n",
    "urs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DW62gZYjKyqs"
   },
   "outputs": [],
   "source": [
    "def extract_pleiadesID(url):\n",
    "    st= str(url)\n",
    "    uri= st[33:] #using string slicing to remove all of the url except the ID, which is at the end\n",
    "    return uri   #because they use consistent URIs, this slice works on every one so yay!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyS6ur9n9b5C"
   },
   "outputs": [],
   "source": [
    "urs['Pleiades_ID1'] = urs['URI1'].apply(lambda x: extract_pleiadesID(x)) #basically just applies above function to every value in the column\n",
    "urs['Pleiades_ID2'] = urs['URI2'].apply(lambda x: extract_pleiadesID(x))\n",
    "urs['Pleiades_ID3'] = urs['URI3'].apply(lambda x: extract_pleiadesID(x))\n",
    "urs['Pleiades_ID4'] = urs['URI4'].apply(lambda x: extract_pleiadesID(x))\n",
    "urs['Pleiades_ID5'] = urs['URI5'].apply(lambda x: extract_pleiadesID(x))\n",
    "#extracting ID from URL\n",
    "#there is probably a more efficient way to do this but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "520TT9vj9yPh"
   },
   "outputs": [],
   "source": [
    "#sanity check to make sure that code worked\n",
    "urs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZgXgehu3xDp"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_coordinates1(pid):\n",
    "    try:\n",
    "        url = f'http://api.pleiades.stoa.org/places/{pid}/json'\n",
    "        r = requests.get(url)\n",
    "        cont = json.loads(r.content)\n",
    "        coordinates = cont['features'][0]['geometry']['coordinates']\n",
    "        if len(coordinates) == 2:\n",
    "          return coordinates\n",
    "        elif len(coordinates[0]) == 2:\n",
    "          return coordinates[0]\n",
    "        elif len(coordinates[0][0]) == 2:\n",
    "          return coordinates[0][0]\n",
    "        else:\n",
    "            return coordinates[0][0][0]   #I could have used list comprehension but this worked and I was grumpy\n",
    "    except:                               #some of the coordinates were lists and some were lists of lists\n",
    "      pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxiII8KR-Wjh"
   },
   "outputs": [],
   "source": [
    "urs['Coordinates1'] = urs['Pleiades_ID1'].apply(lambda x: get_coordinates1(x)) #applying function to values\n",
    "urs['Coordinates2'] = urs['Pleiades_ID2'].apply(lambda x: get_coordinates1(x))\n",
    "urs['Coordinates3'] = urs['Pleiades_ID3'].apply(lambda x: get_coordinates1(x))\n",
    "urs['Coordinates4'] = urs['Pleiades_ID4'].apply(lambda x: get_coordinates1(x))\n",
    "urs['Coordinates5'] = urs['Pleiades_ID5'].apply(lambda x: get_coordinates1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHgKn2IT-rTZ"
   },
   "outputs": [],
   "source": [
    "#sanity check\n",
    "urs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnqnmCizYCB3"
   },
   "outputs": [],
   "source": [
    "def get_feature_description(pid):\n",
    "  try:\n",
    "    url= f'http://api.pleiades.stoa.org/places/{pid}/json'\n",
    "    r = requests.get(url)\n",
    "    cont = json.loads(r.content)\n",
    "    feat_desc= cont['features'][0]['properties']['description']  #tells us a bit more about the feature and data provenance\n",
    "    return feat_desc\n",
    "  except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqDud42QhAli"
   },
   "outputs": [],
   "source": [
    "urs['feature_description1']= urs['Pleiades_ID1'].apply(lambda x: get_feature_description(x))\n",
    "urs['feature_description2']= urs['Pleiades_ID2'].apply(lambda x: get_feature_description(x))\n",
    "urs['feature_description3']= urs['Pleiades_ID3'].apply(lambda x: get_feature_description(x))\n",
    "urs['feature_description4']= urs['Pleiades_ID4'].apply(lambda x: get_feature_description(x))\n",
    "urs['feature_description5']= urs['Pleiades_ID5'].apply(lambda x: get_feature_description(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fg6mDDRqihUR"
   },
   "outputs": [],
   "source": [
    "urs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_GzgeYoZA2a"
   },
   "outputs": [],
   "source": [
    "def get_place_description(pid):\n",
    "  try:\n",
    "    url= f'http://api.pleiades.stoa.org/places/{pid}/json'\n",
    "    r = requests.get(url)\n",
    "    cont = json.loads(r.content)\n",
    "    p_desc= cont['description']\n",
    "    return p_desc\n",
    "  except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJ6RT62YkqUN"
   },
   "outputs": [],
   "source": [
    "urs['place_description1']= urs['Pleiades_ID1'].apply(lambda x: get_place_description(x))\n",
    "urs['place_description2']= urs['Pleiades_ID2'].apply(lambda x: get_place_description(x))\n",
    "urs['place_description3']= urs['Pleiades_ID3'].apply(lambda x: get_place_description(x))\n",
    "urs['place_description4']= urs['Pleiades_ID4'].apply(lambda x: get_place_description(x)) #this sometimes has actual interesting details, otherwise just\n",
    "urs['place_description5']= urs['Pleiades_ID5'].apply(lambda x: get_place_description(x)) #has where it was cited (which is also good!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YMJpDKXlNsx"
   },
   "outputs": [],
   "source": [
    "urs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubqf8aFFCKRX"
   },
   "outputs": [],
   "source": [
    "urs.to_csv('/content/drive/MyDrive/GIS/FinalProject/pleiadesDataC.csv') #this is much more data than we need for map making\n",
    "                                                                        #but saving for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkamKFkwDv22"
   },
   "outputs": [],
   "source": [
    "coordinates1= pd.concat([urs['Ancient_Name'], urs['Pleiades_ID1'],urs['Coordinates1'],urs['place_description1']], axis=1)\n",
    "coordinates2= pd.concat([urs['Ancient_Name'], urs['Pleiades_ID2'],urs['Coordinates2'],urs['place_description2']], axis=1)   #isolating coordinates from\n",
    "coordinates3= pd.concat([urs['Ancient_Name'], urs['Pleiades_ID3'],urs['Coordinates3'],urs['place_description3']], axis=1)   #our much larger dataframe\n",
    "coordinates4= pd.concat([urs['Ancient_Name'], urs['Pleiades_ID4'],urs['Coordinates4'],urs['place_description4']], axis=1)\n",
    "coordinates5= pd.concat([urs['Ancient_Name'], urs['Pleiades_ID5'],urs['Coordinates5'],urs['place_description5']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Etkjp-QF_Te"
   },
   "outputs": [],
   "source": [
    "def return_latitude(lst):\n",
    "  coordinates= lst[0]\n",
    "  return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqY9DkKMHs9p"
   },
   "outputs": [],
   "source": [
    "def return_longitude(lst1):\n",
    "  longitude= lst1[1]\n",
    "  return longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fcou2vb3JODi"
   },
   "outputs": [],
   "source": [
    "coordinates1['latitude1'] = coordinates1['Coordinates1'].dropna().apply(lambda x: return_latitude(x))\n",
    "coordinates2['latitude2'] = coordinates2['Coordinates2'].dropna().apply(lambda x: return_latitude(x))  #once again, just applying function to get latitude to the dataframe\n",
    "coordinates3['latitude3'] = coordinates3['Coordinates3'].dropna().apply(lambda x: return_latitude(x))\n",
    "coordinates4['latitude4'] = coordinates4['Coordinates4'].dropna().apply(lambda x: return_latitude(x))\n",
    "coordinates5['latitude5'] = coordinates5['Coordinates5'].dropna().apply(lambda x: return_latitude(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xa5VBNHbKxnX"
   },
   "outputs": [],
   "source": [
    "coordinates1['longitude1'] = coordinates1['Coordinates1'].dropna().apply(lambda x: return_longitude(x))\n",
    "coordinates2['longitude2'] = coordinates2['Coordinates2'].dropna().apply(lambda x: return_longitude(x))\n",
    "coordinates3['longitude3'] = coordinates3['Coordinates3'].dropna().apply(lambda x: return_longitude(x)) #applying longitude function to dataframe\n",
    "coordinates4['longitude4'] = coordinates4['Coordinates4'].dropna().apply(lambda x: return_longitude(x))\n",
    "coordinates5['longitude5'] = coordinates5['Coordinates5'].dropna().apply(lambda x: return_longitude(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPh0h3XJLG4I"
   },
   "outputs": [],
   "source": [
    "coordinates1.to_csv('/content/drive/MyDrive/GIS/FinalProject/Coordinates_Data/Coordinates1.csv')\n",
    "coordinates2.to_csv('/content/drive/MyDrive/GIS/FinalProject/Coordinates_Data/Coordinates2.csv')\n",
    "coordinates3.to_csv('/content/drive/MyDrive/GIS/FinalProject/Coordinates_Data/Coordinates3.csv')\n",
    "coordinates4.to_csv('/content/drive/MyDrive/GIS/FinalProject/Coordinates_Data/Coordinates4.csv')\n",
    "coordinates5.to_csv('/content/drive/MyDrive/GIS/FinalProject/Coordinates_Data/Coordinates5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEpdXvSTkQtY"
   },
   "outputs": [],
   "source": [
    "def get_place_name(pid):  #I didn't end up using this function because it wasn't always super useful\n",
    "  try:                    #But keeping it just in case it could be useful in the future\n",
    "    url= f'http://api.pleiades.stoa.org/places/{pid}/json'\n",
    "    r = requests.get(url)\n",
    "    cont = json.loads(r.content)\n",
    "    id_name= cont['features'][0]['id']\n",
    "    return id_name\n",
    "  except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML862CRYkxzz"
   },
   "outputs": [],
   "source": [
    "urs['place_text']= urs['Pleiades_ID'].apply(lambda x: get_place_name(x))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
